---
title: Analysis
description: Provide a detailed analysis using more sophisticated statistics techniques.
toc: true
draft: false
---
![](images/MMRpics.jpeg)


### Introduction
# Motivation
- Variable
- Question to answer 
- Objectives
- Outline of models (This will include figures/tables that illustrate aspects of the data of your question.)

# Explain the flaws and limitations of your analysis



### Conclusion




As shown in the data page, we find out the unexpected positive growth of the maternal mortality rate over the States. In effort to figure out the possible reasons that has statistical significance causing this increasing trend, our group seek to explore if the annual spending on healthcare and the average age of pregnancy could contribute to the phenomenon. 

Our team focus on the following variables:

  - Demographic factors : race group, year, location
  - Other factors : spending on healthcare, average age of pregnancy.

We collected and cleaned the average spending of healthcare data and the average pregnancy age data. During the analyzing process, we notice a clear increasing trend in both the line plot of spending vs mmr and avaergae age vs mmr. Thus, we predict that a linear regression may provide a fit model for the deduction.



# Analysis
```{r load in the data, echo=FALSE}
suppressPackageStartupMessages(library(tidyverse))
load(here::here("dataset/mmr.RData"))
```

```{r figure 3, echo=FALSE}
mmr_data_clean |>
  group_by(year_id, location_name, race_group) |>
  filter(str_detect(location_name, "Census")) |> 
  summarize(mean = mean(val))|>
  ggplot(aes(x = year_id, y = mean)) +
  geom_line(aes(color = location_name)) + 
  facet_wrap(~race_group) + 
  labs(
    title = "Maternal Mortality by Census Region over Time, Faceted by Race",
    x = "Mean Maternal Mortality Ratio",
    y = "Year",
    color = "Census Region"
  )

```

Figure 3: The five graphs depict the trajectory of maternal mortality rates over a 20-year period, differentiated by racial categories and geographic regions in the United States.  These categories include Hispanic and any race, Non-Hispanic American Indian and Alaska Native, Non-Hispanic Asian and Native Hawaiian or Other Pacific Islander, Non-Hispanic Black, and Non-Hispanic White.  While there is an overarching increase in mortality rates across these racial demographics, the patterns of increase vary notably between them.

For the categories of Hispanic and any race, Non-Hispanic Asian and Native Hawaiian or Other Pacific Islander, and Non-Hispanic White, the mortality rates appear to be relatively stable, with slight fluctuations over the two decades.  The lines on the graph for these groups are relatively flat, suggesting less volatility in their yearly rates and possibly better outcomes when compared to the other categories.

Contrastingly, the Non-Hispanic Black category exhibits a pronounced upward trend in the Northeast and South regions, indicating a concerning rise in maternal mortality rates that surpasses the other racial groups in these areas.  This suggests that Non-Hispanic Black women in these regions are disproportionately affected by factors contributing to maternal mortality.

The Non-Hispanic American Indian and Alaska Native category demonstrates a significant increase in maternal mortality rates, particularly in the Midwest and West regions.  The sharp rise could be indicative of systemic health disparities or regional deficiencies in healthcare access or quality that particularly impact this demographic.

The observed regional differences, such as higher rates in the South and variations in the Midwest and West, might be influenced by a multitude of factors including healthcare infrastructure, socioeconomic status, accessibility of prenatal and postnatal care, and population density.  Regions with higher population densities might face different healthcare challenges than less densely populated areas, potentially affecting the availability and quality of care.


```{r figure 5, echo=FALSE}
# Load necessary libraries
library(ggplot2)
library(readr)

# Load the dataset
data_path = "dataset/phc_mmr_with_age.csv"
combined_data <- read_csv(data_path, show_col_types = FALSE)

# Ensure spending and mean_val are numeric
combined_data$spending <- as.numeric(combined_data$spending)
combined_data$mean_val <- as.numeric(combined_data$mean_val)
combined_data$year <- as.factor(combined_data$year)

# Plot spending vs mean_val (MMR) faceted by year
ggplot(combined_data, aes(x = spending, y = mean_val)) + 
  geom_point(aes(alpha = 0.5)) +
  facet_wrap(~ year) +
  theme_minimal() +
  labs(
    title = "Maternal Mortality vs. Healthcare Spending by Year",
    x = "Spending",
    y = "MMR"
  ) +
  theme(legend.position = "none")

```


```{r figure 9, echo=FALSE, null = FALSE}
# Load the necessary libraries
library(ggplot2)
library(readr)

# Load the dataset
data_path <- "dataset/phc_mmr_with_age.csv"
data <- read_csv(data_path, show_col_types = FALSE)

# Check for non-numeric values in the AverageAge column
data$AverageAge <- suppressWarnings(as.numeric(data$AverageAge))

# Filter out rows with NA values in critical columns
data <- data[!is.na(data$AverageAge) & !is.na(data$spending) & !is.na(data$Region), ]

# Ensure spending is numeric
data$spending <- suppressWarnings(as.numeric(data$spending))

# Create a bubble chart with fitted lines by Region
ggplot(data, aes(x = spending, y = AverageAge, color = Region)) +
  geom_point(aes(size = 3), alpha = 0.6) +  
  geom_smooth(method = "lm", se = FALSE, aes(group = Region)) +  
  scale_size_identity() +  
  labs(title = "Bubble Chart with Fitted Lines by Region",
       x = "Healthcare Spending",
       y = "Average Age of Pregnancy",
       color = "Region") +
  theme_minimal() +
  facet_wrap(~ Region)

```


# Model Findings

### Simple Linear Regression for MMR-AGE
```{r, echo=FALSE, warning = FALSE}
# Load necessary packages
library(broom)
library(knitr)

data <- read_csv("dataset/phc_mmr_with_age.csv", show_col_types = FALSE)
data$AverageAge <- as.integer(data$AverageAge)

data$mean_val <- data$mean_val / 100
# Fit the simple linear regression model with AverageAge as the predictor
model <- lm(mean_val ~ AverageAge, data = data)

# Tidy the regression coefficients
coefficients_table <- tidy(model)

# Gather model statistics
model_summary <- summary(model)
fit_statistics <- data.frame(
  Metric = c("R-squared", "Adjusted R-squared", "Sigma", "F-statistic", "p-value", "Degrees of Freedom"),
  Value = c(
    model_summary$r.squared,
    model_summary$adj.r.squared,
    model_summary$sigma,
    model_summary$fstatistic[1],
    pf(model_summary$fstatistic[1], model_summary$fstatistic[2], model_summary$fstatistic[3], lower.tail = FALSE),
    model_summary$fstatistic[2]
  )
)

# Output the coefficients table
kable(
  coefficients_table,
  col.names = c("Term", "Estimate", "Standard Error", "t-Statistic", "p-Value"),
  caption = "Regression Coefficients Table"
)

```
1. **Coefficient for AverageAge**: The coefficient estimate for `AverageAge` is 0.0216. This indicates that for each additional year increase in the average age, the `mean_val` variable increases by approximately 0.0216 units on average, assuming a linear relationship.

2. **Statistical Significance**: The p-value for `AverageAge` is extremely low (0.0000001), indicating strong statistical significance. This suggests that there is a very low probability that the observed association is due to random chance, implying that `AverageAge` is a significant predictor of `mean_val`.
  
```{r, echo=FALSE, warning = FALSE}

# Output the model fit statistics table
kable(
  fit_statistics,
  col.names = c("Metric", "Value"),
  caption = "Model Fit Statistics Table"
)

```
1. **Model Fit (R-squared and Adjusted R-squared)**: The R-squared value of 0.0385 indicates that approximately 3.85% of the variability in the dependent variable is explained by the model. The adjusted R-squared value of 0.0372 provides a more accurate measure by adjusting for the number of predictors, which is still low, indicating the model does not capture much of the variability.

2. **Model Accuracy (Sigma)**: The sigma value of 0.1225, representing the standard deviation of the residuals, suggests that predictions on average deviate from the actual values by 0.1225 units. This provides insight into the accuracy of the model's predictions.

3. **Model Significance (F-statistic and p-value)**: The F-statistic of 28.51 and the p-value of 0.0000001 indicate that the model is statistically significant, meaning that the relationship between the dependent and independent variables is unlikely due to chance. However, despite statistical significance, the low R-squared indicates that other factors might influence the dependent variable not captured by this model.



### Multiplie Linear Regression for MMR-AGE with Healthcare Spending and Region
To accurately understand maternal mortality rates (MMR) in relation to age, it's essential to consider other influential factors such as healthcare spending and regional differences. Multiple linear regression allows us to assess the combined impact of these factors, providing a more nuanced analysis of how each variable influences MMR while controlling for others.

# Correlation Matrix
```{r, echo=FALSE, warning = FALSE}

# Load the dataset from the uploaded file
data <- read_csv("dataset/phc_mmr_with_age.csv", show_col_types = FALSE)

# Remove rows with missing values in important columns
data <- na.omit(data)

# Convert AverageAge to integer
data$AverageAge <- as.integer(data$AverageAge)

# Convert Region to a factor (if it's not already)
data$Region <- as.factor(data$Region)
data$race_group <- as.factor(data$Region)

# Generate dummy variables for Region
region_dummies <- model.matrix(~ Region - 1, data)

# Combine the numeric data with the dummy variables
numeric_data <- cbind(data[, sapply(data, is.numeric)], region_dummies)

# Compute the correlation matrix
correlation_matrix <- cor(numeric_data, use = "pairwise.complete.obs")

# Create a formal table using kable
kable(correlation_matrix, caption = "Correlation Matrix")
```
· The correlation matrix shows a strong positive correlation between year and healthcare spending (0.855), suggesting that healthcare spending has generally increased over time. It also highlights a moderate positive correlation between `mean_val` (possibly MMR) and `year` (0.573), implying that the target variable might have increased over time, though other factors are also influencing it. 

· The regional dummy variables have low or negative correlations with most other variables, indicating that regional effects might be distinct and not directly correlated with the continuous variables in the matrix.

# Regression 
```{r, echo=FALSE, warning = FALSE, null = FALSE}
# Load necessary libraries
library(readr)
library(knitr)

# Load the dataset
data <- read_csv("dataset/phc_mmr_with_age.csv", show_col_types = FALSE)

# Remove rows with missing or non-numeric values in critical columns
data <- data[complete.cases(data[c("AverageAge", "spending", "mean_val", "Region")]), ]

# Convert AverageAge to integer
data$AverageAge <- as.integer(as.numeric(data$AverageAge))

# Convert Region to a factor and exclude one level to avoid singularities
data$Region <- factor(data$Region)

# Generate dummy variables for Region, excluding the first level to avoid singularities
region_dummies <- model.matrix(~ Region, data)[, -1]

# Combine the numeric data with the dummy variables
mlr_data <- cbind(data[, c("AverageAge", "spending", "mean_val")], region_dummies)

# Fit the multiple linear regression model
mlr_model <- lm(mean_val ~ ., data = mlr_data)

# Get the summary and convert it to a data frame
summary_model <- summary(mlr_model)
coef_table <- as.data.frame(summary_model$coefficients)

# Display the coefficients in a Kable table
kable(coef_table, caption = "Multiple Linear Regression Coefficients")

```
**Effect of Predictors**: 
   - **AverageAge**: With a coefficient of 2.32 (p < 0.001), a unit increase in average age is associated with an estimated increase of 2.32 units in MMR, holding other factors constant. This implies that as the average age of mothers increases, MMR tends to increase.
   - **Spending**: The spending coefficient is 0.00093 (p = 0.015), indicating that each unit increase in healthcare spending is associated with a slight increase in MMR, but the effect is very small. It is generally expected that increasing healthcare spending would reduce maternal mortality rates (MMR). However, since maternal mortality can also be linked to chronic diseases, increased healthcare expenditure does not always directly translate to improved outcomes. Additionally, as individuals are having children later in life compared to previous generations, the probability of maternal mortality may increase, which could contribute to higher healthcare costs without necessarily improving MMR.
   - **Regions**: 
     - **Northeast**: This region has a significant negative coefficient of -6.35 (p < 0.001), suggesting that, compared to the baseline region, the Northeast is associated with a decrease in MMR.
     - **South**: The coefficient for the South is positive (1.64) but not statistically significant (p = 0.202).
     - **West**: The coefficient for the West is 0.91, also not statistically significant (p = 0.483).

# Performance Siginifcane
```{r, echo=FALSE, warning = FALSE}
# Load the data
data <- read_csv("dataset/phc_mmr_with_age.csv", show_col_types = FALSE)

# Remove rows with missing values in critical columns
data <- na.omit(data)

# Convert AverageAge to integer
data$AverageAge <- as.integer(data$AverageAge)

# Convert Region to a factor and exclude one level to avoid singularities
data$Region <- factor(data$Region)

# Generate dummy variables for Region excluding one level
region_dummies <- model.matrix(~ Region, data)[, -1]

# Combine the numeric data with the dummy variables
mlr_data <- cbind(data[, c("AverageAge", "spending", "mean_val")], region_dummies)

# Fit the multiple linear regression model
mlr_model <- lm(mean_val ~ ., data = mlr_data)

# Get the summary and coefficients table
summary_model <- summary(mlr_model)
coef_table <- as.data.frame(summary_model$coefficients)

# Extract additional statistics
r_squared <- summary_model$r.squared
adj_r_squared <- summary_model$adj.r.squared
sigma <- summary_model$sigma
f_statistic <- summary_model$fstatistic[1]
f_pvalue <- pf(summary_model$fstatistic[1], summary_model$fstatistic[2], summary_model$fstatistic[3], lower.tail = FALSE)
df <- summary_model$df[1]
log_lik <- logLik(mlr_model)
aic <- AIC(mlr_model)
bic <- BIC(mlr_model)
deviance <- deviance(mlr_model)
df_residual <- df.residual(mlr_model)
nobs <- nobs(mlr_model)

# Create a summary table
model_stats <- data.frame(
  r.squared = r_squared,
  adj.r.squared = adj_r_squared,
  sigma = sigma,
  statistic = f_statistic,
  p.value = f_pvalue,
  df = df,
  logLik = as.numeric(log_lik),
  AIC = aic,
  BIC = bic,
  deviance = deviance,
  df.residual = df_residual,
  nobs = nobs
)
# Display the model statistics in a Kable table
kable(model_stats, caption = "Multiple Linear Regression Model Statistics")

```
1. **Model Fit (R-squared and Adjusted R-squared)**: The R-squared value of 0.087 suggests that the model explains approximately 8.7% of the variability in maternal mortality rates (MMR). The adjusted R-squared, at 0.080, adjusts for the number of predictors in the model and shows a similar low explanatory power. This indicates that the predictors included in the model (such as AverageAge, spending, and region) explain only a small portion of the variation in MMR.

2. **Model Significance (F-statistic and p-value)**: The F-statistic of 13.44 and the associated p-value of 0 show that the overall model is statistically significant, meaning that the relationship between the predictors and the dependent variable (MMR) is unlikely to have occurred by chance. Despite the statistical significance, the low R-squared values indicate that there are likely other important factors not captured in this model that influence MMR.

3. **Model Diagnostics (Sigma and Log-Likelihood)**: The sigma (residual standard error) of 11.97 reflects the average deviation of the observed MMR values from the predicted values, indicating the model's predictive accuracy. The log-likelihood of -2782.799 provides a measure of the model's fit, with higher values indicating a better fit. The AIC (5579.599) and BIC (5611.595) values also offer measures of the model's goodness-of-fit, helping to compare it with other models.

Residual Plot
```{r, echo=FALSE, warning = FALSE}
# Load the data
data <- read_csv("dataset/phc_mmr_with_age.csv", show_col_types = FALSE)

# Remove rows with missing values in critical columns
data <- na.omit(data)

# Convert AverageAge to integer
data$AverageAge <- as.integer(data$AverageAge)

# Convert Region to a factor and exclude one level to avoid singularities
data$Region <- factor(data$Region)

# Generate dummy variables for Region excluding one level
region_dummies <- model.matrix(~ Region, data)[, -1]

# Combine the numeric data with the dummy variables
mlr_data <- cbind(data[, c("AverageAge", "spending", "mean_val")], region_dummies)

# Fit the multiple linear regression model
mlr_model <- lm(mean_val ~ ., data = mlr_data)

# Create residual plots
# Plot Residuals vs Fitted Values
par(mfrow = c(1, 1))  # Single plot layout
plot(mlr_model, which = 1)  # Residuals vs Fitted

```
The residual plot indicates that the multiple linear regression model generally fits the data well, as evidenced by the mostly random scatter of residuals around zero. However, the presence of slight curvature suggests potential non-linearity in the relationship, and the mild fan shape of the residuals suggests possible heteroscedasticity, meaning that the variability in MMR may increase with higher fitted values. The presence of outliers also suggests that further investigation is needed to ensure these points do not disproportionately influence the model's results.

QQ-Plot
```{r, echo=FALSE, warning = FALSE}
# Load the data
data <- read_csv("dataset/phc_mmr_with_age.csv", show_col_types = FALSE)

# Remove rows with missing values in critical columns
data <- data[complete.cases(data[c("AverageAge", "spending", "mean_val", "Region")]), ]

# Convert AverageAge to numeric and handle missing or non-numeric values
data$AverageAge <- as.numeric(data$AverageAge)

# Convert Region to a factor, ensuring all values are present
data$Region <- factor(data$Region)

# Generate dummy variables for Region, excluding the first level to avoid singularities
region_dummies <- model.matrix(~ Region, data)[, -1]

# Combine the numeric data with the dummy variables
mlr_data <- cbind(data[, c("AverageAge", "spending", "mean_val")], region_dummies)

# Fit the multiple linear regression model
mlr_model <- lm(mean_val ~ ., data = mlr_data)

# Generate QQ plot
qqnorm(resid(mlr_model))
qqline(resid(mlr_model), col = "red")
```
The normal Q-Q plot shows that the residuals of the model generally follow a normal distribution, as most data points align with the diagonal reference line. However, there are notable deviations at the tails, particularly at the upper end, indicating the presence of significant outliers and suggesting that the residuals are not perfectly normal. This lack of normality at the extremes suggests that certain extreme data points might be influencing the model, potentially affecting its assumptions and necessitating further investigation or alternative modeling approaches.

### LOG-LOG Regression Model
The multiple linear regression analysis and diagnostic plots suggest potential issues with outliers and deviations from normality in the data. The residuals show some non-linearity and heteroscedasticity, indicating that the standard linear model might not be fully capturing the relationships among maternal mortality rates (MMR), age, spending, and regional effects. By applying a log-log regression model, we can linearize the relationships among variables, handle skewed data more effectively, and interpret coefficients as elasticities, which measure the percentage change in MMR in response to a 1% change in predictors. This approach can improve the model's fit, stabilize variance, and provide more meaningful insights into the proportional changes affecting maternal mortality.

```{r, echo=FALSE, warning = FALSE}
# Load necessary libraries
library(readr)
library(knitr)

# Load the dataset
data <- read_csv("dataset/phc_mmr_with_age.csv", show_col_types = FALSE)

# Remove rows with missing or invalid values in critical columns
data <- data[data$AverageAge > 0 & data$spending > 0 & data$mean_val > 0 & !is.na(data$Region), ]

# Convert AverageAge to numeric for log transformation
data$AverageAge <- as.numeric(data$AverageAge)

# Apply log transformation to the variables
data$log_AverageAge <- log(data$AverageAge)
data$log_spending <- log(data$spending)
data$log_mean_val <- log(data$mean_val)

# Convert Region to a factor
data$Region <- factor(data$Region)

# Generate dummy variables for Region, excluding the first level to avoid singularities
region_dummies <- model.matrix(~ Region, data)[, -1]

# Combine the log-transformed data with the dummy variables
log_mlr_data <- cbind(data[, c("log_AverageAge", "log_spending", "log_mean_val")], region_dummies)

# Fit the log-log regression model
log_mlr_model <- lm(log_mean_val ~ ., data = log_mlr_data)

# Get the summary and convert it to a data frame
log_summary_model <- summary(log_mlr_model)
log_coef_table <- as.data.frame(log_summary_model$coefficients)

# Display the coefficients in a Kable table
kable(log_coef_table, caption = "Log-Log Multiple Linear Regression Coefficients")

```

1.  **Significant Predictors**: 
   - **log_AverageAge**: With a coefficient of 1.74 and a p-value of 0.005, this predictor is statistically significant, indicating that a 1% increase in the average age is associated with an approximate 1.74% increase in MMR.
   - **log_spending**: The coefficient of 0.52 (p < 0.001) indicates that a 1% increase in spending correlates with an approximate 0.52% increase in MMR, suggesting a positive relationship, possibly reflecting increased healthcare spending without directly reducing mortality rates.

3. **Regional Effects**:
   - **RegionNortheast**: This region has a significant negative coefficient of -0.35 (p < 0.001), suggesting that it is associated with approximately a 35% decrease in MMR compared to the baseline region.
   - **RegionSouth and RegionWest**: Both regions have positive coefficients (0.04 and 0.05, respectively), but their p-values are not significant, indicating no statistically significant difference in MMR compared to the baseline region.
   
   
   
```{r}
# Load necessary libraries
library(readr)
library(knitr)

# Load the dataset
data <- read_csv("dataset/phc_mmr_with_age.csv", show_col_types = FALSE)

# Remove rows with missing or invalid values in critical columns
data <- data[data$AverageAge > 0 & data$spending > 0 & data$mean_val > 0 & !is.na(data$Region), ]

# Convert AverageAge to numeric for log transformation
data$AverageAge <- as.numeric(data$AverageAge)

# Apply log transformation to the variables
data$log_AverageAge <- log(data$AverageAge)
data$log_spending <- log(data$spending)
data$log_mean_val <- log(data$mean_val)

# Convert Region to a factor
data$Region <- factor(data$Region)

# Generate dummy variables for Region, excluding the first level to avoid singularities
region_dummies <- model.matrix(~ Region, data)[, -1]

# Combine the log-transformed data with the dummy variables
log_mlr_data <- cbind(data[, c("log_AverageAge", "log_spending", "log_mean_val")], region_dummies)

# Fit the log-log regression model
log_mlr_model <- lm(log_mean_val ~ ., data = log_mlr_data)

# Extract model summary statistics
log_summary_model <- summary(log_mlr_model)
model_stats <- data.frame(
  R_squared = log_summary_model$r.squared,
  Adj_R_squared = log_summary_model$adj.r.squared,
  Sigma = log_summary_model$sigma,
  Statistic = log_summary_model$fstatistic[1],
  P_value = pf(log_summary_model$fstatistic[1], log_summary_model$fstatistic[2], log_summary_model$fstatistic[3], lower.tail = FALSE),
  DF = log_summary_model$df[1],
  LogLik = as.numeric(logLik(log_mlr_model)),
  AIC = AIC(log_mlr_model),
  BIC = BIC(log_mlr_model),
  Deviance = deviance(log_mlr_model),
  DF_Residual = df.residual(log_mlr_model),
  Nobs = nobs(log_mlr_model)
)

# Display the model statistics in a Kable table
kable(model_stats, caption = "Log-Log Multiple Linear Regression Model Statistics")

```
1. **Model Fit (R-squared and Adjusted R-squared)**: The R-squared value of 0.16 indicates that the model explains approximately 16% of the variability in maternal mortality rates (MMR). The adjusted R-squared value of 0.15, which adjusts for the number of predictors in the model, suggests a slightly reduced explanatory power. This implies that while the model includes some significant predictors, a substantial portion of the variability in MMR remains unexplained, likely due to other factors not included in the model.

2. **Model Significance (F-statistic and p-value)**: The F-statistic of 26.93 and its p-value of zero show that the overall model is statistically significant, meaning that the combined predictors significantly contribute to explaining variations in MMR. However, the relatively low R-squared values still suggest that there are additional important factors influencing MMR that are not captured by this model.

3. **Model Diagnostics (Sigma, Log-Likelihood, AIC, and BIC)**: The sigma (residual standard error) of 0.42 reflects the average deviation of observed log-transformed MMR values from predicted values. The log-likelihood of -388.48 indicates the model's goodness-of-fit, with higher values implying a better fit. The AIC (790.96) and BIC (822.96) values provide comparative measures of fit, penalizing for model complexity. The deviance (124.11) and residual degrees of freedom (708) give additional insight into the model's residuals and flexibility, while the number of observations (714) reflects the sample size.

## QQ and residual
```{r, echo=FALSE, warning = FALSE}
# Load necessary libraries
library(readr)
library(knitr)
library(ggplot2)

# Load the dataset
data <- read_csv("dataset/phc_mmr_with_age.csv", show_col_types = FALSE)

# Remove rows with missing or invalid values in critical columns
data <- data[data$AverageAge > 0 & data$spending > 0 & data$mean_val > 0 & !is.na(data$Region), ]

# Convert AverageAge to numeric for log transformation
data$AverageAge <- as.numeric(data$AverageAge)

# Apply log transformation to the variables
data$log_AverageAge <- log(data$AverageAge)
data$log_spending <- log(data$spending)
data$log_mean_val <- log(data$mean_val)

# Convert Region to a factor
data$Region <- factor(data$Region)

# Generate dummy variables for Region, excluding the first level to avoid singularities
region_dummies <- model.matrix(~ Region, data)[, -1]

# Combine the log-transformed data with the dummy variables
log_mlr_data <- cbind(data[, c("log_AverageAge", "log_spending", "log_mean_val")], region_dummies)

# Fit the log-log regression model
log_mlr_model <- lm(log_mean_val ~ ., data = log_mlr_data)

# Residuals vs Fitted plot
ggplot(data.frame(fitted = fitted(log_mlr_model), residuals = resid(log_mlr_model)), aes(fitted, residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuals vs Fitted Plot", x = "Fitted values", y = "Residuals") +
  theme_minimal()

```
The residuals vs. fitted plot of the log-log regression model shows a more random and consistent distribution of residuals compared to the previous model, indicating a better fit to the data. The spread of residuals is more uniform, suggesting that the log-log model effectively addresses non-linearity and reduces heteroscedasticity, making the variance of residuals more constant. Additionally, there are fewer extreme outliers, which means that the log-log transformation mitigates the influence of extreme data points and provides a more accurate representation of the relationship between maternal mortality rates, age, spending, and regional factors. Despite this improvement, further refinement could enhance the model's overall fit and predictive accuracy.

```{r}
# QQ plot
qqnorm(resid(log_mlr_model))
qqline(resid(log_mlr_model), col = "red")
```
The current normal Q-Q plot shows that the residuals from the log-log regression model generally follow a normal distribution, with most points aligning closely to the diagonal reference line. However, there are slight deviations at the extremes, which are indicative of some outliers affecting the tails. Compared to the previous Q-Q plot, which exhibited more extreme deviations from normality at the upper end, the log-log model demonstrates improved normality of residuals, suggesting that the log transformation helps to mitigate the influence of outliers and enhances the overall fit. Nonetheless, the presence of outliers in both models indicates potential factors influencing the data that are not fully captured in either model.
