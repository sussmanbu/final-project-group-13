[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This comes from the file data.qmd.\nYour first steps in this project will be to find data to work on.\nI recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.\nInitially, you will study one dataset but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable. Data from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components."
  },
  {
    "objectID": "data.html#what-makes-a-good-data-set",
    "href": "data.html#what-makes-a-good-data-set",
    "title": "Data",
    "section": "What makes a good data set?",
    "text": "What makes a good data set?\n\nData you are interested in and care about.\nData where there are a lot of potential questions that you can explore.\nA data set that isn’t completely cleaned already.\nMultiple sources for data that you can combine.\nSome type of time and/or location component."
  },
  {
    "objectID": "data.html#where-to-keep-data",
    "href": "data.html#where-to-keep-data",
    "title": "Data",
    "section": "Where to keep data?",
    "text": "Where to keep data?\nBelow 50mb: In dataset folder\nAbove 50mb: In dataset_ignore folder. This folder will be ignored by git so you’ll have to manually sync these files across your team.\n\nSharing your data\nFor small datasets (&lt;50mb), you can use the dataset folder that is tracked by github. Add the files just like you would any other file.\nIf you create a folder named data this will cause problems.\nFor larger datasets, you’ll need to create a new folder in the project root directory named dataset-ignore. This will be ignored by git (based off the .gitignore file in the project root directory) which will help you avoid issues with Github’s size limits. Your team will have to manually make sure the data files in dataset-ignore are synced across team members.\nYour load_and_clean_data.R file is how you will load and clean your data. Here is a an example of a very simple one.\n\nsource(\n  \"scripts/load_and_clean_data.R\",\n  echo = TRUE # Use echo=FALSE or omit it to avoid code output  \n)\n\n\n&gt; suppressPackageStartupMessages(library(tidyverse))\n\n&gt; mmr_data &lt;- read_csv(here::here(\"dataset\", \"IHME_USA_MMR_STATE_RACE_ETHN_1999_2019_ESTIMATES_Y2023M07D03.CSV\"))\n\n\nRows: 5901 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): measure_name, location_name, race_group, sex_name, age_group_name, ...\ndbl (9): measure_id, location_id, sex_id, age_group_id, year_id, metric_id, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n&gt; mmr_data_clean &lt;- mmr_data\n\n&gt; mmr_data_clean &lt;- reframe(mmr_data, location_id, location_name, \n+     race_group, year_id, val, lower, upper)\n\n&gt; write_csv(mmr_data_clean, file = here::here(\"dataset\", \n+     \"mmr_clean.csv\"))\n\n&gt; save(mmr_data_clean, file = here::here(\"dataset/mmr.RData\"))\n\n\nYou should never use absolute paths (eg. /Users/danielsussman/path/to/project/ or C:\\MA415\\\\Final_Project\\).\nYou might consider using the here function from the here package to avoid path problems.\n\n\nLoad and clean data script\nThe idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them. This file might create a derivative data set that you then use for your subsequent analysis. Note that you don’t need to run this script from every post/page. Instead, you can load in the results of this script, which could be plain text files or .RData files. In your data page you’ll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes. To link to this file, you can use [cleaning script](/scripts/load_and_clean_data.R) wich appears as cleaning script."
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones and summarize the rest.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your load_and_clean_data.R file.\nRrename variables and recode factors to make data more clear.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your load_and_clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "Analysis",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this\n&gt; To be or not to be.\n\nTo be or not to be."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 7, 2024 at 11:59pm.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblog-post-3\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2024\n\n\nChristy\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 2\n\n\n\n\n\nExploring the data background and describing our loading and cleaning process \n\n\n\n\n\nMar 18, 2024\n\n\nChristy\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Blog Post\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2024\n\n\nGroup 13\n\n\n\n\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post. \n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting. \n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-02-23-first-blog-post/first-blog-post.html",
    "href": "posts/2024-02-23-first-blog-post/first-blog-post.html",
    "title": "First Blog Post",
    "section": "",
    "text": "Here are the three data sets we are considering for our analysis. Each data set enables us to study racial disparities in different sectors in the United States."
  },
  {
    "objectID": "posts/2024-02-23-first-blog-post/first-blog-post.html#united-states-maternal-mortality-ratio-estimates-by-race-and-ethnicity-1999-2019",
    "href": "posts/2024-02-23-first-blog-post/first-blog-post.html#united-states-maternal-mortality-ratio-estimates-by-race-and-ethnicity-1999-2019",
    "title": "First Blog Post",
    "section": "United States Maternal Mortality Ratio Estimates by Race and Ethnicity 1999-2019",
    "text": "United States Maternal Mortality Ratio Estimates by Race and Ethnicity 1999-2019\nhttps://ghdx.healthdata.org/record/ihme-data/united-states-maternal-mortality-by-state-race-ethnicity-1999-2019\nThese data come from the Institute for Health Metrics and Evaluation and are supported by the Global Health Data Exchange. This set of data contains multiple spreadsheets, however I will focus on the most detailed one. It presents maternal mortality ratios for women in the United States from the ages 10-54 for the years 1999-2019. It divides the data into each state with a national observation, as well as separating into five racial categories. The thirteen columns right as it is downloaded are measure_id, measure_name, location_id, location_name, race_group, sex_id, age_group_id, age_group_name, year_id, metric_id, val, lower, and upper. Some of the columns have the same value for every observation in its raw form and will likely not be relevant to our analysis, like measure_id, measure_name, and age_group_id. Columns like location_name (the name of the state), race_group (the race of the individual), year (the year of the observation), and val (the maternal mortality ratio) will likely be most relevant to our analysis. There are 5901 rows of observations in the data set. The data set is very accessible, simply requiring an account to download. It comes in CSV form. It is quite clean already, however, pivoting the data or making subtables would likely aid in our analysis given its current organization. Some questions we can look at with this data are: “How does maternal mortality change over time? How does maternal mortality vary across US states? How does maternal mortality vary across ethnic groups?” At a deeper level, we could investigate how maternal mortality varies across both state and race groups, and compare with additional data about healthcare for different racial groups to add on a new data set. A possible challenge comes in interpreting the value for the maternal mortality ratio. The value is given along with a lower and upper value, however it is not clear how this number should be interpreted for the analysis. More research is needed here."
  },
  {
    "objectID": "posts/2024-02-23-first-blog-post/first-blog-post.html#mental-health-care-in-the-last-4-weeks-2020-2022",
    "href": "posts/2024-02-23-first-blog-post/first-blog-post.html#mental-health-care-in-the-last-4-weeks-2020-2022",
    "title": "First Blog Post",
    "section": "Mental Health Care in the Last 4 Weeks 2020-2022",
    "text": "Mental Health Care in the Last 4 Weeks 2020-2022\nhttps://catalog.data.gov/dataset/mental-health-care-in-the-last-4-weeks\nThis dataset provides information on mental health care situations around the United States. The government wants to collect this data to gauge the impact of the pandemic on employment status, consumer spending, food security, housing, education disruptions, and dimensions of physical and mental wellness. This particular data focuses on the mental health situation during the pandemic. The survey was originally conducted by an internet questionnaire and the sample frame is the Census Bureau Master Address File Data. The columns of the data include Indicator, group, state, subgroups, phases of treatment, time period of treatment, in which the subgroups label specifies the race, age, and gender of the individuals. The dataset rows first divide the survey takers into separate groups according to the types of treatment and mental health counseling done during the pandemic season.\nThis data is pretty accessible in CSV form. It’s a bit messy with separate subgroups under the column indicator which refer to different types and level of mental health treatment. The main problem that comes across during the data cleaning process is to reevaluate the existing group and split the groups by race, county, and state. I do think the different criteria and the design of the questionnaire make the results messy and less ideal. Some questions we can look at with this data set are: Is there a racial difference across the States of mental health treatment performance during the pandemic? Which part of America is recorded to be the biggest state of mental health care during the quarantine period? A possible challenge we might face is to find a way to filter the data and regenerate an ideal form if data where the subgroups are divided in a logical way."
  },
  {
    "objectID": "posts/2024-02-23-first-blog-post/first-blog-post.html#united-states-ethnic-group-versus-income-level-2022",
    "href": "posts/2024-02-23-first-blog-post/first-blog-post.html#united-states-ethnic-group-versus-income-level-2022",
    "title": "First Blog Post",
    "section": "United States Ethnic Group versus Income Level 2022",
    "text": "United States Ethnic Group versus Income Level 2022\nhttps://usa.ipums.org/usa-action/variables/group\nThe dataset is extracted from IPUMS which mainly explores the relationship between US ethnic group and their income level in 2022. There are 19 columns with over nine million rows. The data are collected mainly through the survey; it is composed of microdata. Each data row indicates a person, with all characteristics numerically coded. The data can be loaded in csv. format and has already been coded into numbers which is easily to be cleaned and the main focus might be the correction of the data record with missing values.\nThere are some questions we derived from this data: 1. What is the relationship between the ICTWAGE and race, does sex affect it? 2. Do you think PERWT will affect the outcome of question 1? 3. Which race increase their income most as they getting older. The challenges we have maybe hard to graph with multi variables such as age. We need to group them in a specific range first and then graph them. In addition, the missing value may affect the outcomes. What’s more, as we have 9 millions data, we are not sure it will need more time to process the data. We may need to filter out some of the useless data."
  },
  {
    "objectID": "posts/2024-03-18-blog-post-2/blog-post-2.html",
    "href": "posts/2024-03-18-blog-post-2/blog-post-2.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "The Institute for Health Metrics and Evaluation (IHME), a global health research organization at the University of Washington, generated and released the dataset. The purpose of creating and collecting this dataset was to provide insights into maternal mortality trends within the United States, focusing on the disparities among different racial and ethnic groups. This effort aligns with the broader objectives of improving maternal health outcomes and addressing health disparities. As for accessing the original source of the data, there is a “Data input source list” included in the release files which could be part of the original source providing raw materials.\n\n\n\nThis data is likely to rely on multiple sources including vital statistics systems, death certificates and also medical records. The discrepancies in reporting across the states and areas may introduce bias to the final dataset. The sample population for this dataset consists of maternal deaths occurring in the United States from 1999 to 2019. However, certain groups such as racial or ethnic minorities could be disproportionately affected by maternal mortality, but less likely to get high-quality healthcare. This situation might not be reflected directly in the final dataset.\n\n\n\nThere are other researchers used this data to analyze the questions of the mortality rate across different ethnicity groups in Trends in state-level maternal mortality by racial and ethnic group in the United States (2023). Their question is: How does maternal mortality vary by state and race and ethnicity over time in the US?\nThere are a couple of policies in the US about maternal mortality rate such as: 1. The Maternal Mortality Review Committees (MMRCs) at the state level, which analyze maternal death cases and provide recommendations. 2. The Preventing Maternal Deaths Act, which supports states in establishing and expanding MMRCs. 3. State-specific initiatives like California’s Maternal Quality Care Collaborative, which develops strategies to reduce maternal mortality and morbidity. 4. Federal funding for rural maternal health initiatives and research on maternal health disparities. Maybe some of them would use this data.\n[https://jamanetwork.com/journals/jama/fullarticle/2806661]"
  },
  {
    "objectID": "posts/2024-03-18-blog-post-2/blog-post-2.html#data-background",
    "href": "posts/2024-03-18-blog-post-2/blog-post-2.html#data-background",
    "title": "Blog Post 2",
    "section": "",
    "text": "The Institute for Health Metrics and Evaluation (IHME), a global health research organization at the University of Washington, generated and released the dataset. The purpose of creating and collecting this dataset was to provide insights into maternal mortality trends within the United States, focusing on the disparities among different racial and ethnic groups. This effort aligns with the broader objectives of improving maternal health outcomes and addressing health disparities. As for accessing the original source of the data, there is a “Data input source list” included in the release files which could be part of the original source providing raw materials.\n\n\n\nThis data is likely to rely on multiple sources including vital statistics systems, death certificates and also medical records. The discrepancies in reporting across the states and areas may introduce bias to the final dataset. The sample population for this dataset consists of maternal deaths occurring in the United States from 1999 to 2019. However, certain groups such as racial or ethnic minorities could be disproportionately affected by maternal mortality, but less likely to get high-quality healthcare. This situation might not be reflected directly in the final dataset.\n\n\n\nThere are other researchers used this data to analyze the questions of the mortality rate across different ethnicity groups in Trends in state-level maternal mortality by racial and ethnic group in the United States (2023). Their question is: How does maternal mortality vary by state and race and ethnicity over time in the US?\nThere are a couple of policies in the US about maternal mortality rate such as: 1. The Maternal Mortality Review Committees (MMRCs) at the state level, which analyze maternal death cases and provide recommendations. 2. The Preventing Maternal Deaths Act, which supports states in establishing and expanding MMRCs. 3. State-specific initiatives like California’s Maternal Quality Care Collaborative, which develops strategies to reduce maternal mortality and morbidity. 4. Federal funding for rural maternal health initiatives and research on maternal health disparities. Maybe some of them would use this data.\n[https://jamanetwork.com/journals/jama/fullarticle/2806661]"
  },
  {
    "objectID": "posts/2024-03-18-blog-post-2/blog-post-2.html#data-loading-and-cleaning",
    "href": "posts/2024-03-18-blog-post-2/blog-post-2.html#data-loading-and-cleaning",
    "title": "Blog Post 2",
    "section": "Data Loading and Cleaning",
    "text": "Data Loading and Cleaning\nThe data comes from the Institute for Health Metrics and Evaluation and is supported by the Global Health Data Exchange. The file we chose initially has columns measure_id, measure_name, location_id, location_name, race_group, sex_id, age_group_id, age_group_name, year_id, metric_id, val, lower, and upper. It has 5901 observations. This odd number indicates that there may be some missing observations for certain location/race/year combinations. To load the data, we made an account and downloaded the .csv file called IHME_USA_MMR_STATE_RACE_ETHN_1999_2019_ESTIMATES_Y2023M07D03. We then read it into a dataframe in R. Since the data is already very clean, we simply selected the columns location_id, location_name, race_group, year_id, val, lower, upper to keep in our cleaned dataset and discarded the rest. We chose to discard those columns because every observation had the same value. For example, every observation was Female in the age group 10 to 54. We then saved this cleaned dataframe as a .Rdata file in our repository."
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2024-03-29-blogpost3/blogpost3.html",
    "href": "posts/2024-03-29-blogpost3/blogpost3.html",
    "title": "blog-post-3",
    "section": "",
    "text": "In the context of maternal mortality data disaggregated by race and ethnicity, transparency is critical in understanding how racial and ethnic disaggregation is defined and applied, data sources, and data collection methods that may influence the interpretation of results. Dataset has provided detailed documentation of data sources, methods, and acknowledges any gaps or uncertainties in the data. Limitations may include incomplete data due to underreporting, differences in data collection methods between states or agencies, and challenges in capturing the complexity of racial and ethnic identity in a standardized manner. Transparency of these limits is essential to prevent misuse of data, such as oversimplified narratives that may mask the underlying causes of disparities in maternal mortality. Second, good deeds require maximization of benefits and minimization of harm. For maternal mortality data, this means ensuring that data is collected, analysed and disseminated without prejudice to the communities represented, and that survey results are used equitably to improve maternal health outcomes. To uphold this principle, one limitation of practicing philanthropy may be the challenge of balancing the need for detailed data to identify differences with the risk of stigmatizing specific communities. Finally, justice involves a fair distribution of benefits and burdens. These limitations can be structural barriers to the equitable implementation of interventions, such as systemic racism in the health care system and socioeconomic inequalities that affect health outcomes."
  },
  {
    "objectID": "posts/2024-03-29-blogpost3/blogpost3.html#data-equity-analysis",
    "href": "posts/2024-03-29-blogpost3/blogpost3.html#data-equity-analysis",
    "title": "blog-post-3",
    "section": "",
    "text": "In the context of maternal mortality data disaggregated by race and ethnicity, transparency is critical in understanding how racial and ethnic disaggregation is defined and applied, data sources, and data collection methods that may influence the interpretation of results. Dataset has provided detailed documentation of data sources, methods, and acknowledges any gaps or uncertainties in the data. Limitations may include incomplete data due to underreporting, differences in data collection methods between states or agencies, and challenges in capturing the complexity of racial and ethnic identity in a standardized manner. Transparency of these limits is essential to prevent misuse of data, such as oversimplified narratives that may mask the underlying causes of disparities in maternal mortality. Second, good deeds require maximization of benefits and minimization of harm. For maternal mortality data, this means ensuring that data is collected, analysed and disseminated without prejudice to the communities represented, and that survey results are used equitably to improve maternal health outcomes. To uphold this principle, one limitation of practicing philanthropy may be the challenge of balancing the need for detailed data to identify differences with the risk of stigmatizing specific communities. Finally, justice involves a fair distribution of benefits and burdens. These limitations can be structural barriers to the equitable implementation of interventions, such as systemic racism in the health care system and socioeconomic inequalities that affect health outcomes."
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team Group 13. The members of this team are below."
  },
  {
    "objectID": "about.html#guanchen-li",
    "href": "about.html#guanchen-li",
    "title": "About",
    "section": "Guanchen Li",
    "text": "Guanchen Li\nI’m a junior at BU majoring in Pure and Applied Math with CS Minor.\nhttps://github.com/Guanchenlileo"
  },
  {
    "objectID": "about.html#yueyou-tao",
    "href": "about.html#yueyou-tao",
    "title": "About",
    "section": "Yueyou Tao",
    "text": "Yueyou Tao\njunior, Stats major Anthropology minor\nhttps://github.com/yueyouTao"
  },
  {
    "objectID": "about.html#jiajun-chen",
    "href": "about.html#jiajun-chen",
    "title": "About",
    "section": "Jiajun Chen",
    "text": "Jiajun Chen\nI am junior student major in Math & Econ.\nhttps://github.com/nora-cc"
  },
  {
    "objectID": "about.html#yulin-chen",
    "href": "about.html#yulin-chen",
    "title": "About",
    "section": "Yulin Chen",
    "text": "Yulin Chen\nI am a junior studying Econ & Maths\nhttps://github.com/ChristyKK"
  },
  {
    "objectID": "about.html#jessica-sherr",
    "href": "about.html#jessica-sherr",
    "title": "About",
    "section": "Jessica Sherr",
    "text": "Jessica Sherr\nI’m a senior at BU majoring in Economics and Mathematics with a CS Minor.\nhttps://github.com/jessicasherr\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.Rmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Try to write in the style of a news or popular article. Importantly, this pge should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nInteractive\nYou will also be required to make an interactive dashboard like this one.\nYour Big Data page should include a link to an interactive dashboard. The dashboard should be created either using Shiny or FlexDashboard (or another tool with professor’s approval). This interactive component should in some way support your thesis from your big picture page. Good interactives often provide both high-level understanding of the data while allowing a user to investigate specific scenarios, observations, subgroups, etc.\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions from the Big Picture? Plotly with default hover text will get no credit. Be creative!\n\n\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  }
]